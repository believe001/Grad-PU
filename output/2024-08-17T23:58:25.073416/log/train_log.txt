这是加了attention注意力机制和dropout还有DepthwiseSeparableConv的结果
[2024-08-17 23:58:25,074::train::INFO] Experiment ID: 2024-08-17T23:58:25.073416
[2024-08-17 23:58:25,074::train::INFO] ========== Build Model ==========
[2024-08-17 23:58:26,604::train::INFO] === The number of parameters in model: 80.1680 K === 
[2024-08-17 23:58:26,605::train::INFO] Namespace(batch_size=16, beta=0.01, block_num=3, bn_size=1, ckpt_path='./pretrained_model/pugan/ckpt/ckpt-epoch-60.pth', dataset='pugan', double_4X=False, epochs=60, feat_dim=32, gamma=0.5, growth_rate=32, h5_file_path='./data/PU-GAN/train/PUGAN_poisson_256_poisson_1024.h5', jitter_max=0.03, jitter_sigma=0.01, k=16, layer_num=3, local_sigma=0.02, lr=0.001, lr_decay_step=20, max_dist=0.2, num_iterations=10, num_points=256, num_workers=4, optim='adam', out_path='./output', patch_rate=3, print_rate=200, save_dir='pcd', save_rate=10, seed=21, skip_rate=1, test_input_path='./data/PU-GAN/test_pointcloud/input_2048_4X/input_2048/', test_step_size=50, truncate_distance=False, up_rate=4, use_random_input=True, use_smooth_loss=False, weight_decay=0)
[2024-08-17 23:58:26,606::train::INFO] P2PNet(
  (feature_extractor): FeatureExtractor(
    (conv_init): Sequential(
      (0): Conv1d(3, 32, kernel_size=(1,), stride=(1,))
      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (dense_blocks): ModuleList(
      (0): ModuleList(
        (0): DenseUnit(
          (dense_layers): ModuleList(
            (0): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
            (1): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
            (2): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(96, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
          )
        )
        (1): Transition(
          (trans): Sequential(
            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
      (1): ModuleList(
        (0): DenseUnit(
          (dense_layers): ModuleList(
            (0): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
            (1): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
            (2): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(96, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
          )
        )
        (1): Transition(
          (trans): Sequential(
            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
      (2): ModuleList(
        (0): DenseUnit(
          (dense_layers): ModuleList(
            (0): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
            (1): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
            (2): DenseLayer(
              (conv_bottle): Sequential(
                (0): Conv1d(96, 32, kernel_size=(1,), stride=(1,))
                (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU(inplace=True)
              )
              (point_conv): Point3DConv(
                (conv_delta): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1), groups=3)
                    (pointwise): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (conv_feats): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
                (post_conv): Sequential(
                  (0): DepthwiseSeparableConv(
                    (depthwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), groups=32)
                    (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
                  )
                  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                  (2): ReLU(inplace=True)
                )
              )
              (attention): SelfAttention(
                (query): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (key): Conv1d(32, 4, kernel_size=(1,), stride=(1,))
                (value): Conv1d(32, 32, kernel_size=(1,), stride=(1,))
              )
            )
          )
        )
        (1): Transition(
          (trans): Sequential(
            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,))
            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
          )
        )
      )
    )
  )
  (p2p_regressor): P2PRegressor(
    (mlp_0): Conv1d(163, 64, kernel_size=(1,), stride=(1,))
    (mlp_1): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
    (mlp_2): Conv1d(32, 16, kernel_size=(1,), stride=(1,))
    (mlp_3): Conv1d(16, 1, kernel_size=(1,), stride=(1,))
    (actvn): ReLU()
  )
  (dropout): Dropout(p=0.5, inplace=False)
)
[2024-08-17 23:58:26,608::train::INFO] ========== Begin Training ==========
[2024-08-17 23:58:26,608::train::INFO] ********* Epoch 1 *********
[2024-08-17 23:59:25,943::train::INFO] epoch: 1/60, iters: 200/1500, loss: 30.660302
[2024-08-18 00:00:26,569::train::INFO] epoch: 1/60, iters: 400/1500, loss: 29.610913
[2024-08-18 00:01:29,771::train::INFO] epoch: 1/60, iters: 600/1500, loss: 29.283578
[2024-08-18 00:02:35,330::train::INFO] epoch: 1/60, iters: 800/1500, loss: 29.121581
[2024-08-18 00:03:42,372::train::INFO] epoch: 1/60, iters: 1000/1500, loss: 29.016269
[2024-08-18 00:04:50,358::train::INFO] epoch: 1/60, iters: 1200/1500, loss: 28.958329
[2024-08-18 00:05:58,524::train::INFO] epoch: 1/60, iters: 1400/1500, loss: 28.900585
[2024-08-18 00:06:32,759::train::INFO] epoch: 1/60, avg epoch loss: 28.873845, time: 8 mins 11.5 secs
[2024-08-18 00:06:32,760::train::INFO] ********* Epoch 2 *********
[2024-08-18 00:07:41,907::train::INFO] epoch: 2/60, iters: 200/1500, loss: 28.639656
[2024-08-18 00:08:51,237::train::INFO] epoch: 2/60, iters: 400/1500, loss: 28.564921
[2024-08-18 00:10:00,468::train::INFO] epoch: 2/60, iters: 600/1500, loss: 28.587137
[2024-08-18 00:11:09,926::train::INFO] epoch: 2/60, iters: 800/1500, loss: 28.597988
[2024-08-18 00:12:19,428::train::INFO] epoch: 2/60, iters: 1000/1500, loss: 28.593597
[2024-08-18 00:13:28,943::train::INFO] epoch: 2/60, iters: 1200/1500, loss: 28.595956
[2024-08-18 00:14:38,584::train::INFO] epoch: 2/60, iters: 1400/1500, loss: 28.599313
[2024-08-18 00:15:13,217::train::INFO] epoch: 2/60, avg epoch loss: 28.594379, time: 16 mins 51.9 secs
[2024-08-18 00:15:13,217::train::INFO] ********* Epoch 3 *********
[2024-08-18 00:16:23,069::train::INFO] epoch: 3/60, iters: 200/1500, loss: 28.672268
[2024-08-18 00:17:32,556::train::INFO] epoch: 3/60, iters: 400/1500, loss: 28.614662
[2024-08-18 00:18:42,887::train::INFO] epoch: 3/60, iters: 600/1500, loss: 23.630984
[2024-08-18 00:19:53,492::train::INFO] epoch: 3/60, iters: 800/1500, loss: 20.045947
[2024-08-18 00:21:03,920::train::INFO] epoch: 3/60, iters: 1000/1500, loss: 17.881443
[2024-08-18 00:22:14,639::train::INFO] epoch: 3/60, iters: 1200/1500, loss: 16.441031
[2024-08-18 00:23:25,702::train::INFO] epoch: 3/60, iters: 1400/1500, loss: 15.405202
[2024-08-18 00:24:01,112::train::INFO] epoch: 3/60, avg epoch loss: 14.987852, time: 25 mins 39.8 secs
[2024-08-18 00:24:01,112::train::INFO] ********* Epoch 4 *********
[2024-08-18 00:25:11,682::train::INFO] epoch: 4/60, iters: 200/1500, loss: 9.165450
[2024-08-18 00:26:22,445::train::INFO] epoch: 4/60, iters: 400/1500, loss: 9.157887
[2024-08-18 00:27:33,112::train::INFO] epoch: 4/60, iters: 600/1500, loss: 9.155746
[2024-08-18 00:28:43,680::train::INFO] epoch: 4/60, iters: 800/1500, loss: 9.158818
[2024-08-18 00:29:54,174::train::INFO] epoch: 4/60, iters: 1000/1500, loss: 9.153566
[2024-08-18 00:31:04,988::train::INFO] epoch: 4/60, iters: 1200/1500, loss: 9.151897
[2024-08-18 00:32:15,778::train::INFO] epoch: 4/60, iters: 1400/1500, loss: 9.144219
[2024-08-18 00:32:50,963::train::INFO] epoch: 4/60, avg epoch loss: 9.141719, time: 34 mins 29.7 secs
[2024-08-18 00:32:50,963::train::INFO] ********* Epoch 5 *********
[2024-08-18 00:34:01,616::train::INFO] epoch: 5/60, iters: 200/1500, loss: 9.186528
[2024-08-18 00:35:12,123::train::INFO] epoch: 5/60, iters: 400/1500, loss: 9.149104
[2024-08-18 00:36:22,515::train::INFO] epoch: 5/60, iters: 600/1500, loss: 9.154582
[2024-08-18 00:37:32,711::train::INFO] epoch: 5/60, iters: 800/1500, loss: 9.145705
[2024-08-18 00:38:43,264::train::INFO] epoch: 5/60, iters: 1000/1500, loss: 9.145777
[2024-08-18 00:39:53,756::train::INFO] epoch: 5/60, iters: 1200/1500, loss: 9.141166
[2024-08-18 00:41:04,080::train::INFO] epoch: 5/60, iters: 1400/1500, loss: 9.138587
[2024-08-18 00:41:38,990::train::INFO] epoch: 5/60, avg epoch loss: 9.135833, time: 43 mins 17.7 secs
[2024-08-18 00:41:38,990::train::INFO] ********* Epoch 6 *********
[2024-08-18 00:42:49,712::train::INFO] epoch: 6/60, iters: 200/1500, loss: 9.173831
[2024-08-18 00:43:59,962::train::INFO] epoch: 6/60, iters: 400/1500, loss: 9.172240
[2024-08-18 00:45:10,443::train::INFO] epoch: 6/60, iters: 600/1500, loss: 9.158455
[2024-08-18 00:46:21,237::train::INFO] epoch: 6/60, iters: 800/1500, loss: 9.147773
[2024-08-18 00:47:31,931::train::INFO] epoch: 6/60, iters: 1000/1500, loss: 9.137771
[2024-08-18 00:48:42,472::train::INFO] epoch: 6/60, iters: 1200/1500, loss: 9.132241
[2024-08-18 00:49:53,453::train::INFO] epoch: 6/60, iters: 1400/1500, loss: 9.125053
[2024-08-18 00:50:28,872::train::INFO] epoch: 6/60, avg epoch loss: 9.120542, time: 52 mins 7.6 secs
[2024-08-18 00:50:28,873::train::INFO] ********* Epoch 7 *********
[2024-08-18 00:51:39,595::train::INFO] epoch: 7/60, iters: 200/1500, loss: 9.144390
[2024-08-18 00:52:49,857::train::INFO] epoch: 7/60, iters: 400/1500, loss: 9.143243
[2024-08-18 00:54:00,561::train::INFO] epoch: 7/60, iters: 600/1500, loss: 9.140086
[2024-08-18 00:55:10,809::train::INFO] epoch: 7/60, iters: 800/1500, loss: 9.133513
[2024-08-18 00:56:21,362::train::INFO] epoch: 7/60, iters: 1000/1500, loss: 9.122328
[2024-08-18 00:57:32,169::train::INFO] epoch: 7/60, iters: 1200/1500, loss: 9.123692
[2024-08-18 00:58:43,007::train::INFO] epoch: 7/60, iters: 1400/1500, loss: 9.118797
[2024-08-18 00:59:18,099::train::INFO] epoch: 7/60, avg epoch loss: 9.119601, time: 60 mins 56.8 secs
[2024-08-18 00:59:18,099::train::INFO] ********* Epoch 8 *********
[2024-08-18 01:00:28,802::train::INFO] epoch: 8/60, iters: 200/1500, loss: 9.095472
[2024-08-18 01:01:39,432::train::INFO] epoch: 8/60, iters: 400/1500, loss: 9.107064
[2024-08-18 01:02:50,028::train::INFO] epoch: 8/60, iters: 600/1500, loss: 9.101224
[2024-08-18 01:04:00,621::train::INFO] epoch: 8/60, iters: 800/1500, loss: 9.103009
[2024-08-18 01:05:11,154::train::INFO] epoch: 8/60, iters: 1000/1500, loss: 9.102896
[2024-08-18 01:06:21,885::train::INFO] epoch: 8/60, iters: 1200/1500, loss: 9.103893
[2024-08-18 01:07:32,593::train::INFO] epoch: 8/60, iters: 1400/1500, loss: 9.104732
[2024-08-18 01:08:07,923::train::INFO] epoch: 8/60, avg epoch loss: 9.102842, time: 69 mins 46.6 secs
[2024-08-18 01:08:07,924::train::INFO] ********* Epoch 9 *********
[2024-08-18 01:09:18,621::train::INFO] epoch: 9/60, iters: 200/1500, loss: 9.105590
[2024-08-18 01:10:29,392::train::INFO] epoch: 9/60, iters: 400/1500, loss: 9.111613
[2024-08-18 01:11:40,140::train::INFO] epoch: 9/60, iters: 600/1500, loss: 9.108345
[2024-08-18 01:12:50,967::train::INFO] epoch: 9/60, iters: 800/1500, loss: 9.107555
[2024-08-18 01:14:02,047::train::INFO] epoch: 9/60, iters: 1000/1500, loss: 9.100649
[2024-08-18 01:15:13,138::train::INFO] epoch: 9/60, iters: 1200/1500, loss: 9.101436
[2024-08-18 01:16:24,377::train::INFO] epoch: 9/60, iters: 1400/1500, loss: 9.101673
[2024-08-18 01:16:59,779::train::INFO] epoch: 9/60, avg epoch loss: 9.100698, time: 78 mins 38.5 secs
[2024-08-18 01:16:59,779::train::INFO] ********* Epoch 10 *********
[2024-08-18 01:18:11,007::train::INFO] epoch: 10/60, iters: 200/1500, loss: 9.092764
[2024-08-18 01:19:22,056::train::INFO] epoch: 10/60, iters: 400/1500, loss: 9.105448
[2024-08-18 01:20:32,820::train::INFO] epoch: 10/60, iters: 600/1500, loss: 9.109890
[2024-08-18 01:21:43,569::train::INFO] epoch: 10/60, iters: 800/1500, loss: 9.108884
[2024-08-18 01:22:54,195::train::INFO] epoch: 10/60, iters: 1000/1500, loss: 9.100493
[2024-08-18 01:24:05,053::train::INFO] epoch: 10/60, iters: 1200/1500, loss: 9.099689
[2024-08-18 01:25:15,373::train::INFO] epoch: 10/60, iters: 1400/1500, loss: 9.095144
[2024-08-18 01:25:50,519::train::INFO] epoch: 10/60, avg epoch loss: 9.097508, time: 87 mins 29.2 secs
[2024-08-18 01:25:50,532::train::INFO] ********* Epoch 11 *********
[2024-08-18 01:27:01,339::train::INFO] epoch: 11/60, iters: 200/1500, loss: 9.120591
[2024-08-18 01:28:11,955::train::INFO] epoch: 11/60, iters: 400/1500, loss: 9.110872
[2024-08-18 01:29:22,877::train::INFO] epoch: 11/60, iters: 600/1500, loss: 9.107866
[2024-08-18 01:30:34,059::train::INFO] epoch: 11/60, iters: 800/1500, loss: 9.099595
[2024-08-18 01:31:45,232::train::INFO] epoch: 11/60, iters: 1000/1500, loss: 9.097277
[2024-08-18 01:32:56,390::train::INFO] epoch: 11/60, iters: 1200/1500, loss: 9.094912
[2024-08-18 01:34:07,614::train::INFO] epoch: 11/60, iters: 1400/1500, loss: 9.096831
[2024-08-18 01:34:42,890::train::INFO] epoch: 11/60, avg epoch loss: 9.092472, time: 96 mins 21.6 secs
[2024-08-18 01:34:42,890::train::INFO] ********* Epoch 12 *********
[2024-08-18 01:35:53,728::train::INFO] epoch: 12/60, iters: 200/1500, loss: 9.125096
[2024-08-18 01:37:04,613::train::INFO] epoch: 12/60, iters: 400/1500, loss: 9.101273
[2024-08-18 01:38:15,177::train::INFO] epoch: 12/60, iters: 600/1500, loss: 9.087463
[2024-08-18 01:39:25,829::train::INFO] epoch: 12/60, iters: 800/1500, loss: 9.079983
[2024-08-18 01:40:36,823::train::INFO] epoch: 12/60, iters: 1000/1500, loss: 9.079752
[2024-08-18 01:41:47,511::train::INFO] epoch: 12/60, iters: 1200/1500, loss: 9.075105
[2024-08-18 01:42:58,013::train::INFO] epoch: 12/60, iters: 1400/1500, loss: 9.070460
[2024-08-18 01:43:33,255::train::INFO] epoch: 12/60, avg epoch loss: 9.065845, time: 105 mins 12.0 secs
[2024-08-18 01:43:33,255::train::INFO] ********* Epoch 13 *********
[2024-08-18 01:44:44,117::train::INFO] epoch: 13/60, iters: 200/1500, loss: 9.046181
[2024-08-18 01:45:54,962::train::INFO] epoch: 13/60, iters: 400/1500, loss: 9.045843
[2024-08-18 01:47:05,964::train::INFO] epoch: 13/60, iters: 600/1500, loss: 9.049880
[2024-08-18 01:48:17,074::train::INFO] epoch: 13/60, iters: 800/1500, loss: 9.044821
[2024-08-18 01:49:28,394::train::INFO] epoch: 13/60, iters: 1000/1500, loss: 9.035367
[2024-08-18 01:50:39,302::train::INFO] epoch: 13/60, iters: 1200/1500, loss: 9.036176
[2024-08-18 01:51:50,126::train::INFO] epoch: 13/60, iters: 1400/1500, loss: 9.033651
[2024-08-18 01:52:25,619::train::INFO] epoch: 13/60, avg epoch loss: 9.029816, time: 114 mins 4.3 secs
[2024-08-18 01:52:25,619::train::INFO] ********* Epoch 14 *********
[2024-08-18 01:53:36,808::train::INFO] epoch: 14/60, iters: 200/1500, loss: 8.994835
[2024-08-18 01:54:47,531::train::INFO] epoch: 14/60, iters: 400/1500, loss: 9.019878
[2024-08-18 01:55:58,434::train::INFO] epoch: 14/60, iters: 600/1500, loss: 9.015941
[2024-08-18 01:57:09,099::train::INFO] epoch: 14/60, iters: 800/1500, loss: 9.015015
[2024-08-18 01:58:19,706::train::INFO] epoch: 14/60, iters: 1000/1500, loss: 9.012188
[2024-08-18 01:59:29,932::train::INFO] epoch: 14/60, iters: 1200/1500, loss: 9.013604
[2024-08-18 02:00:40,689::train::INFO] epoch: 14/60, iters: 1400/1500, loss: 9.010805
[2024-08-18 02:01:15,767::train::INFO] epoch: 14/60, avg epoch loss: 9.010252, time: 122 mins 54.5 secs
[2024-08-18 02:01:15,767::train::INFO] ********* Epoch 15 *********
[2024-08-18 02:02:26,464::train::INFO] epoch: 15/60, iters: 200/1500, loss: 8.996472
[2024-08-18 02:03:37,418::train::INFO] epoch: 15/60, iters: 400/1500, loss: 9.018669
[2024-08-18 02:04:48,302::train::INFO] epoch: 15/60, iters: 600/1500, loss: 9.016096
[2024-08-18 02:05:59,440::train::INFO] epoch: 15/60, iters: 800/1500, loss: 9.013202
[2024-08-18 02:07:10,034::train::INFO] epoch: 15/60, iters: 1000/1500, loss: 9.003077
[2024-08-18 02:08:20,518::train::INFO] epoch: 15/60, iters: 1200/1500, loss: 8.998491
[2024-08-18 02:09:30,810::train::INFO] epoch: 15/60, iters: 1400/1500, loss: 8.995617
[2024-08-18 02:10:05,911::train::INFO] epoch: 15/60, avg epoch loss: 8.994389, time: 131 mins 44.6 secs
[2024-08-18 02:10:05,912::train::INFO] ********* Epoch 16 *********
[2024-08-18 02:11:16,447::train::INFO] epoch: 16/60, iters: 200/1500, loss: 9.003585
[2024-08-18 02:12:27,193::train::INFO] epoch: 16/60, iters: 400/1500, loss: 9.003240
[2024-08-18 02:13:37,830::train::INFO] epoch: 16/60, iters: 600/1500, loss: 8.995485
[2024-08-18 02:14:48,257::train::INFO] epoch: 16/60, iters: 800/1500, loss: 8.986441
[2024-08-18 02:15:59,024::train::INFO] epoch: 16/60, iters: 1000/1500, loss: 8.971043
[2024-08-18 02:17:09,942::train::INFO] epoch: 16/60, iters: 1200/1500, loss: 8.968310
[2024-08-18 02:18:21,008::train::INFO] epoch: 16/60, iters: 1400/1500, loss: 8.962965
[2024-08-18 02:18:56,498::train::INFO] epoch: 16/60, avg epoch loss: 8.959210, time: 140 mins 35.2 secs
[2024-08-18 02:18:56,498::train::INFO] ********* Epoch 17 *********
[2024-08-18 02:20:07,473::train::INFO] epoch: 17/60, iters: 200/1500, loss: 8.940449
[2024-08-18 02:21:17,963::train::INFO] epoch: 17/60, iters: 400/1500, loss: 8.930892
[2024-08-18 02:22:28,350::train::INFO] epoch: 17/60, iters: 600/1500, loss: 8.934862
[2024-08-18 02:23:39,075::train::INFO] epoch: 17/60, iters: 800/1500, loss: 8.926033
[2024-08-18 02:24:49,850::train::INFO] epoch: 17/60, iters: 1000/1500, loss: 8.925796
[2024-08-18 02:26:00,658::train::INFO] epoch: 17/60, iters: 1200/1500, loss: 8.925795
[2024-08-18 02:27:11,276::train::INFO] epoch: 17/60, iters: 1400/1500, loss: 8.917942
[2024-08-18 02:27:46,445::train::INFO] epoch: 17/60, avg epoch loss: 8.916201, time: 149 mins 25.2 secs
[2024-08-18 02:27:46,445::train::INFO] ********* Epoch 18 *********
[2024-08-18 02:28:57,222::train::INFO] epoch: 18/60, iters: 200/1500, loss: 8.906946
[2024-08-18 02:30:07,914::train::INFO] epoch: 18/60, iters: 400/1500, loss: 8.911985
[2024-08-18 02:31:18,791::train::INFO] epoch: 18/60, iters: 600/1500, loss: 8.907767
[2024-08-18 02:32:29,775::train::INFO] epoch: 18/60, iters: 800/1500, loss: 8.905283
[2024-08-18 02:33:40,829::train::INFO] epoch: 18/60, iters: 1000/1500, loss: 8.900942
[2024-08-18 02:34:51,408::train::INFO] epoch: 18/60, iters: 1200/1500, loss: 8.899328
[2024-08-18 02:36:02,423::train::INFO] epoch: 18/60, iters: 1400/1500, loss: 8.897413
[2024-08-18 02:36:37,857::train::INFO] epoch: 18/60, avg epoch loss: 8.897800, time: 158 mins 16.6 secs
[2024-08-18 02:36:37,857::train::INFO] ********* Epoch 19 *********
[2024-08-18 02:37:48,711::train::INFO] epoch: 19/60, iters: 200/1500, loss: 8.878957
[2024-08-18 02:38:59,360::train::INFO] epoch: 19/60, iters: 400/1500, loss: 8.883445
[2024-08-18 02:40:09,845::train::INFO] epoch: 19/60, iters: 600/1500, loss: 8.888381
[2024-08-18 02:41:20,183::train::INFO] epoch: 19/60, iters: 800/1500, loss: 8.884181
[2024-08-18 02:42:30,548::train::INFO] epoch: 19/60, iters: 1000/1500, loss: 8.878230
[2024-08-18 02:43:41,091::train::INFO] epoch: 19/60, iters: 1200/1500, loss: 8.875914
[2024-08-18 02:44:51,605::train::INFO] epoch: 19/60, iters: 1400/1500, loss: 8.872478
[2024-08-18 02:45:26,942::train::INFO] epoch: 19/60, avg epoch loss: 8.871496, time: 167 mins 5.7 secs
[2024-08-18 02:45:26,942::train::INFO] ********* Epoch 20 *********
[2024-08-18 02:46:37,548::train::INFO] epoch: 20/60, iters: 200/1500, loss: 8.870763
[2024-08-18 02:47:48,060::train::INFO] epoch: 20/60, iters: 400/1500, loss: 8.875763
[2024-08-18 02:48:58,468::train::INFO] epoch: 20/60, iters: 600/1500, loss: 8.864327
[2024-08-18 02:50:08,876::train::INFO] epoch: 20/60, iters: 800/1500, loss: 8.857754
[2024-08-18 02:51:19,716::train::INFO] epoch: 20/60, iters: 1000/1500, loss: 8.853601
[2024-08-18 02:52:30,236::train::INFO] epoch: 20/60, iters: 1200/1500, loss: 8.858741
[2024-08-18 02:53:40,610::train::INFO] epoch: 20/60, iters: 1400/1500, loss: 8.854824
[2024-08-18 02:54:15,690::train::INFO] epoch: 20/60, avg epoch loss: 8.855369, time: 175 mins 54.4 secs
[2024-08-18 02:54:15,704::train::INFO] ********* Epoch 21 *********
[2024-08-18 02:55:26,437::train::INFO] epoch: 21/60, iters: 200/1500, loss: 8.822445
[2024-08-18 02:56:37,023::train::INFO] epoch: 21/60, iters: 400/1500, loss: 8.826379
[2024-08-18 02:57:47,437::train::INFO] epoch: 21/60, iters: 600/1500, loss: 8.824190
[2024-08-18 02:58:58,156::train::INFO] epoch: 21/60, iters: 800/1500, loss: 8.824556
[2024-08-18 03:00:08,682::train::INFO] epoch: 21/60, iters: 1000/1500, loss: 8.819849
[2024-08-18 03:01:19,490::train::INFO] epoch: 21/60, iters: 1200/1500, loss: 8.822317
[2024-08-18 03:02:30,106::train::INFO] epoch: 21/60, iters: 1400/1500, loss: 8.819633
[2024-08-18 03:03:05,366::train::INFO] epoch: 21/60, avg epoch loss: 8.817836, time: 184 mins 44.1 secs
[2024-08-18 03:03:05,366::train::INFO] ********* Epoch 22 *********
[2024-08-18 03:04:16,037::train::INFO] epoch: 22/60, iters: 200/1500, loss: 8.838839
[2024-08-18 03:05:26,601::train::INFO] epoch: 22/60, iters: 400/1500, loss: 8.817314
[2024-08-18 03:06:37,304::train::INFO] epoch: 22/60, iters: 600/1500, loss: 8.822702
[2024-08-18 03:07:47,952::train::INFO] epoch: 22/60, iters: 800/1500, loss: 8.821995
[2024-08-18 03:08:58,625::train::INFO] epoch: 22/60, iters: 1000/1500, loss: 8.814096
[2024-08-18 03:10:09,236::train::INFO] epoch: 22/60, iters: 1200/1500, loss: 8.810495
[2024-08-18 03:11:20,172::train::INFO] epoch: 22/60, iters: 1400/1500, loss: 8.810527
[2024-08-18 03:11:55,502::train::INFO] epoch: 22/60, avg epoch loss: 8.808439, time: 193 mins 34.2 secs
[2024-08-18 03:11:55,502::train::INFO] ********* Epoch 23 *********
[2024-08-18 03:13:06,655::train::INFO] epoch: 23/60, iters: 200/1500, loss: 8.818673
[2024-08-18 03:14:17,620::train::INFO] epoch: 23/60, iters: 400/1500, loss: 8.809197
[2024-08-18 03:15:28,330::train::INFO] epoch: 23/60, iters: 600/1500, loss: 8.813119
[2024-08-18 03:16:39,213::train::INFO] epoch: 23/60, iters: 800/1500, loss: 8.805444
[2024-08-18 03:17:50,021::train::INFO] epoch: 23/60, iters: 1000/1500, loss: 8.800452
[2024-08-18 03:19:01,123::train::INFO] epoch: 23/60, iters: 1200/1500, loss: 8.796005
[2024-08-18 03:20:12,280::train::INFO] epoch: 23/60, iters: 1400/1500, loss: 8.798478
[2024-08-18 03:20:47,718::train::INFO] epoch: 23/60, avg epoch loss: 8.795897, time: 202 mins 26.4 secs
[2024-08-18 03:20:47,719::train::INFO] ********* Epoch 24 *********
[2024-08-18 03:21:59,030::train::INFO] epoch: 24/60, iters: 200/1500, loss: 8.819543
[2024-08-18 03:23:10,313::train::INFO] epoch: 24/60, iters: 400/1500, loss: 8.796378
[2024-08-18 03:24:21,340::train::INFO] epoch: 24/60, iters: 600/1500, loss: 8.794163
[2024-08-18 03:25:32,104::train::INFO] epoch: 24/60, iters: 800/1500, loss: 8.793390
[2024-08-18 03:26:42,947::train::INFO] epoch: 24/60, iters: 1000/1500, loss: 8.790370
[2024-08-18 03:27:53,514::train::INFO] epoch: 24/60, iters: 1200/1500, loss: 8.790976
[2024-08-18 03:29:03,945::train::INFO] epoch: 24/60, iters: 1400/1500, loss: 8.787933
[2024-08-18 03:29:39,206::train::INFO] epoch: 24/60, avg epoch loss: 8.786670, time: 211 mins 17.9 secs
[2024-08-18 03:29:39,206::train::INFO] ********* Epoch 25 *********
[2024-08-18 03:30:50,259::train::INFO] epoch: 25/60, iters: 200/1500, loss: 8.782106
[2024-08-18 03:32:01,277::train::INFO] epoch: 25/60, iters: 400/1500, loss: 8.788739
[2024-08-18 03:33:12,181::train::INFO] epoch: 25/60, iters: 600/1500, loss: 8.790331
[2024-08-18 03:34:23,060::train::INFO] epoch: 25/60, iters: 800/1500, loss: 8.791902
[2024-08-18 03:35:34,029::train::INFO] epoch: 25/60, iters: 1000/1500, loss: 8.791907
[2024-08-18 03:36:45,049::train::INFO] epoch: 25/60, iters: 1200/1500, loss: 8.785546
[2024-08-18 03:37:56,002::train::INFO] epoch: 25/60, iters: 1400/1500, loss: 8.781852
[2024-08-18 03:38:31,360::train::INFO] epoch: 25/60, avg epoch loss: 8.779353, time: 220 mins 10.1 secs
[2024-08-18 03:38:31,360::train::INFO] ********* Epoch 26 *********
[2024-08-18 03:39:42,143::train::INFO] epoch: 26/60, iters: 200/1500, loss: 8.777110
[2024-08-18 03:40:52,752::train::INFO] epoch: 26/60, iters: 400/1500, loss: 8.761180
[2024-08-18 03:42:03,378::train::INFO] epoch: 26/60, iters: 600/1500, loss: 8.762488
[2024-08-18 03:43:14,090::train::INFO] epoch: 26/60, iters: 800/1500, loss: 8.767147
[2024-08-18 03:44:24,884::train::INFO] epoch: 26/60, iters: 1000/1500, loss: 8.765100
[2024-08-18 03:45:35,401::train::INFO] epoch: 26/60, iters: 1200/1500, loss: 8.769235
[2024-08-18 03:46:46,116::train::INFO] epoch: 26/60, iters: 1400/1500, loss: 8.770465
[2024-08-18 03:47:21,583::train::INFO] epoch: 26/60, avg epoch loss: 8.770709, time: 229 mins 0.3 secs
[2024-08-18 03:47:21,583::train::INFO] ********* Epoch 27 *********
[2024-08-18 03:48:32,573::train::INFO] epoch: 27/60, iters: 200/1500, loss: 8.771480
[2024-08-18 03:49:43,323::train::INFO] epoch: 27/60, iters: 400/1500, loss: 8.763306
[2024-08-18 03:50:54,037::train::INFO] epoch: 27/60, iters: 600/1500, loss: 8.762003
[2024-08-18 03:52:04,945::train::INFO] epoch: 27/60, iters: 800/1500, loss: 8.764552
[2024-08-18 03:53:15,426::train::INFO] epoch: 27/60, iters: 1000/1500, loss: 8.762580
[2024-08-18 03:54:26,017::train::INFO] epoch: 27/60, iters: 1200/1500, loss: 8.764022
[2024-08-18 03:55:36,884::train::INFO] epoch: 27/60, iters: 1400/1500, loss: 8.765202
[2024-08-18 03:56:12,342::train::INFO] epoch: 27/60, avg epoch loss: 8.764436, time: 237 mins 51.1 secs
[2024-08-18 03:56:12,342::train::INFO] ********* Epoch 28 *********
[2024-08-18 03:57:23,484::train::INFO] epoch: 28/60, iters: 200/1500, loss: 8.790557
[2024-08-18 03:58:34,531::train::INFO] epoch: 28/60, iters: 400/1500, loss: 8.771368
[2024-08-18 03:59:45,586::train::INFO] epoch: 28/60, iters: 600/1500, loss: 8.770567
[2024-08-18 04:00:56,249::train::INFO] epoch: 28/60, iters: 800/1500, loss: 8.767350
[2024-08-18 04:02:07,142::train::INFO] epoch: 28/60, iters: 1000/1500, loss: 8.763506
[2024-08-18 04:03:17,964::train::INFO] epoch: 28/60, iters: 1200/1500, loss: 8.764776
[2024-08-18 04:04:28,938::train::INFO] epoch: 28/60, iters: 1400/1500, loss: 8.762983
[2024-08-18 04:05:04,365::train::INFO] epoch: 28/60, avg epoch loss: 8.762212, time: 246 mins 43.1 secs
[2024-08-18 04:05:04,365::train::INFO] ********* Epoch 29 *********
[2024-08-18 04:06:15,479::train::INFO] epoch: 29/60, iters: 200/1500, loss: 8.773342
[2024-08-18 04:07:26,353::train::INFO] epoch: 29/60, iters: 400/1500, loss: 8.760122
[2024-08-18 04:08:37,050::train::INFO] epoch: 29/60, iters: 600/1500, loss: 8.757151
[2024-08-18 04:09:47,628::train::INFO] epoch: 29/60, iters: 800/1500, loss: 8.755566
[2024-08-18 04:10:58,303::train::INFO] epoch: 29/60, iters: 1000/1500, loss: 8.753513
[2024-08-18 04:12:09,378::train::INFO] epoch: 29/60, iters: 1200/1500, loss: 8.755742
[2024-08-18 04:13:20,518::train::INFO] epoch: 29/60, iters: 1400/1500, loss: 8.754088
[2024-08-18 04:13:55,724::train::INFO] epoch: 29/60, avg epoch loss: 8.753367, time: 255 mins 34.4 secs
[2024-08-18 04:13:55,725::train::INFO] ********* Epoch 30 *********
[2024-08-18 04:15:06,697::train::INFO] epoch: 30/60, iters: 200/1500, loss: 8.758633
[2024-08-18 04:16:17,357::train::INFO] epoch: 30/60, iters: 400/1500, loss: 8.748856
[2024-08-18 04:17:27,776::train::INFO] epoch: 30/60, iters: 600/1500, loss: 8.751253
[2024-08-18 04:18:38,595::train::INFO] epoch: 30/60, iters: 800/1500, loss: 8.751269
[2024-08-18 04:19:49,662::train::INFO] epoch: 30/60, iters: 1000/1500, loss: 8.748990
[2024-08-18 04:21:00,723::train::INFO] epoch: 30/60, iters: 1200/1500, loss: 8.747079
[2024-08-18 04:22:11,851::train::INFO] epoch: 30/60, iters: 1400/1500, loss: 8.747963
[2024-08-18 04:22:47,198::train::INFO] epoch: 30/60, avg epoch loss: 8.748733, time: 264 mins 25.9 secs
[2024-08-18 04:22:47,211::train::INFO] ********* Epoch 31 *********
[2024-08-18 04:23:58,195::train::INFO] epoch: 31/60, iters: 200/1500, loss: 8.769741
[2024-08-18 04:25:08,910::train::INFO] epoch: 31/60, iters: 400/1500, loss: 8.756890
[2024-08-18 04:26:19,525::train::INFO] epoch: 31/60, iters: 600/1500, loss: 8.755461
[2024-08-18 04:27:30,142::train::INFO] epoch: 31/60, iters: 800/1500, loss: 8.753219
[2024-08-18 04:28:41,026::train::INFO] epoch: 31/60, iters: 1000/1500, loss: 8.750918
[2024-08-18 04:29:52,065::train::INFO] epoch: 31/60, iters: 1200/1500, loss: 8.751425
[2024-08-18 04:31:02,894::train::INFO] epoch: 31/60, iters: 1400/1500, loss: 8.751663
[2024-08-18 04:31:38,228::train::INFO] epoch: 31/60, avg epoch loss: 8.750414, time: 273 mins 16.9 secs
[2024-08-18 04:31:38,229::train::INFO] ********* Epoch 32 *********
[2024-08-18 04:32:49,074::train::INFO] epoch: 32/60, iters: 200/1500, loss: 8.749572
[2024-08-18 04:33:59,967::train::INFO] epoch: 32/60, iters: 400/1500, loss: 8.748247
[2024-08-18 04:35:10,852::train::INFO] epoch: 32/60, iters: 600/1500, loss: 8.745214
[2024-08-18 04:36:21,947::train::INFO] epoch: 32/60, iters: 800/1500, loss: 8.751452
[2024-08-18 04:37:32,720::train::INFO] epoch: 32/60, iters: 1000/1500, loss: 8.751529
[2024-08-18 04:38:43,755::train::INFO] epoch: 32/60, iters: 1200/1500, loss: 8.749687
[2024-08-18 04:39:54,531::train::INFO] epoch: 32/60, iters: 1400/1500, loss: 8.747764
[2024-08-18 04:40:29,817::train::INFO] epoch: 32/60, avg epoch loss: 8.746899, time: 282 mins 8.5 secs
[2024-08-18 04:40:29,817::train::INFO] ********* Epoch 33 *********
[2024-08-18 04:41:40,562::train::INFO] epoch: 33/60, iters: 200/1500, loss: 8.743765
[2024-08-18 04:42:51,179::train::INFO] epoch: 33/60, iters: 400/1500, loss: 8.738660
[2024-08-18 04:44:01,877::train::INFO] epoch: 33/60, iters: 600/1500, loss: 8.742123
[2024-08-18 04:45:12,303::train::INFO] epoch: 33/60, iters: 800/1500, loss: 8.742856
[2024-08-18 04:46:22,906::train::INFO] epoch: 33/60, iters: 1000/1500, loss: 8.738146
[2024-08-18 04:47:33,850::train::INFO] epoch: 33/60, iters: 1200/1500, loss: 8.741354
[2024-08-18 04:48:44,828::train::INFO] epoch: 33/60, iters: 1400/1500, loss: 8.741843
[2024-08-18 04:49:20,025::train::INFO] epoch: 33/60, avg epoch loss: 8.740691, time: 290 mins 58.7 secs
[2024-08-18 04:49:20,025::train::INFO] ********* Epoch 34 *********
[2024-08-18 04:50:30,541::train::INFO] epoch: 34/60, iters: 200/1500, loss: 8.733493
[2024-08-18 04:51:41,269::train::INFO] epoch: 34/60, iters: 400/1500, loss: 8.720113
[2024-08-18 04:52:51,926::train::INFO] epoch: 34/60, iters: 600/1500, loss: 8.730586
[2024-08-18 04:54:02,590::train::INFO] epoch: 34/60, iters: 800/1500, loss: 8.734961
[2024-08-18 04:55:13,372::train::INFO] epoch: 34/60, iters: 1000/1500, loss: 8.733107
[2024-08-18 04:56:24,207::train::INFO] epoch: 34/60, iters: 1200/1500, loss: 8.737062
[2024-08-18 04:57:35,036::train::INFO] epoch: 34/60, iters: 1400/1500, loss: 8.738210
[2024-08-18 04:58:10,437::train::INFO] epoch: 34/60, avg epoch loss: 8.737307, time: 299 mins 49.1 secs
[2024-08-18 04:58:10,437::train::INFO] ********* Epoch 35 *********
[2024-08-18 04:59:21,345::train::INFO] epoch: 35/60, iters: 200/1500, loss: 8.760245
[2024-08-18 05:00:32,207::train::INFO] epoch: 35/60, iters: 400/1500, loss: 8.746227
[2024-08-18 05:01:43,062::train::INFO] epoch: 35/60, iters: 600/1500, loss: 8.738057
[2024-08-18 05:02:53,985::train::INFO] epoch: 35/60, iters: 800/1500, loss: 8.737080
[2024-08-18 05:04:05,119::train::INFO] epoch: 35/60, iters: 1000/1500, loss: 8.732164
[2024-08-18 05:05:16,179::train::INFO] epoch: 35/60, iters: 1200/1500, loss: 8.735547
[2024-08-18 05:06:27,126::train::INFO] epoch: 35/60, iters: 1400/1500, loss: 8.736759
[2024-08-18 05:07:02,342::train::INFO] epoch: 35/60, avg epoch loss: 8.734691, time: 308 mins 41.1 secs
[2024-08-18 05:07:02,342::train::INFO] ********* Epoch 36 *********
[2024-08-18 05:08:13,149::train::INFO] epoch: 36/60, iters: 200/1500, loss: 8.737850
[2024-08-18 05:09:24,361::train::INFO] epoch: 36/60, iters: 400/1500, loss: 8.725945
[2024-08-18 05:10:35,416::train::INFO] epoch: 36/60, iters: 600/1500, loss: 8.723183
[2024-08-18 05:11:46,072::train::INFO] epoch: 36/60, iters: 800/1500, loss: 8.724299
[2024-08-18 05:12:56,778::train::INFO] epoch: 36/60, iters: 1000/1500, loss: 8.726213
[2024-08-18 05:14:07,107::train::INFO] epoch: 36/60, iters: 1200/1500, loss: 8.729265
[2024-08-18 05:15:17,729::train::INFO] epoch: 36/60, iters: 1400/1500, loss: 8.730493
[2024-08-18 05:15:53,138::train::INFO] epoch: 36/60, avg epoch loss: 8.729876, time: 317 mins 31.8 secs
[2024-08-18 05:15:53,138::train::INFO] ********* Epoch 37 *********
[2024-08-18 05:17:03,819::train::INFO] epoch: 37/60, iters: 200/1500, loss: 8.731960
[2024-08-18 05:18:14,458::train::INFO] epoch: 37/60, iters: 400/1500, loss: 8.734900
[2024-08-18 05:19:25,243::train::INFO] epoch: 37/60, iters: 600/1500, loss: 8.726405
[2024-08-18 05:20:36,037::train::INFO] epoch: 37/60, iters: 800/1500, loss: 8.727672
[2024-08-18 05:21:47,114::train::INFO] epoch: 37/60, iters: 1000/1500, loss: 8.726615
[2024-08-18 05:22:58,072::train::INFO] epoch: 37/60, iters: 1200/1500, loss: 8.730221
[2024-08-18 05:24:08,979::train::INFO] epoch: 37/60, iters: 1400/1500, loss: 8.730482
[2024-08-18 05:24:44,256::train::INFO] epoch: 37/60, avg epoch loss: 8.730710, time: 326 mins 23.0 secs
[2024-08-18 05:24:44,256::train::INFO] ********* Epoch 38 *********
[2024-08-18 05:25:54,886::train::INFO] epoch: 38/60, iters: 200/1500, loss: 8.737678
[2024-08-18 05:27:05,409::train::INFO] epoch: 38/60, iters: 400/1500, loss: 8.726924
[2024-08-18 05:28:15,778::train::INFO] epoch: 38/60, iters: 600/1500, loss: 8.728049
[2024-08-18 05:29:26,385::train::INFO] epoch: 38/60, iters: 800/1500, loss: 8.726859
[2024-08-18 05:30:37,390::train::INFO] epoch: 38/60, iters: 1000/1500, loss: 8.723836
[2024-08-18 05:31:48,173::train::INFO] epoch: 38/60, iters: 1200/1500, loss: 8.725705
[2024-08-18 05:32:58,969::train::INFO] epoch: 38/60, iters: 1400/1500, loss: 8.727596
[2024-08-18 05:33:34,548::train::INFO] epoch: 38/60, avg epoch loss: 8.728493, time: 335 mins 13.3 secs
[2024-08-18 05:33:34,548::train::INFO] ********* Epoch 39 *********
[2024-08-18 05:34:45,986::train::INFO] epoch: 39/60, iters: 200/1500, loss: 8.741077
[2024-08-18 05:35:56,539::train::INFO] epoch: 39/60, iters: 400/1500, loss: 8.723626
[2024-08-18 05:37:07,183::train::INFO] epoch: 39/60, iters: 600/1500, loss: 8.717613
[2024-08-18 05:38:17,851::train::INFO] epoch: 39/60, iters: 800/1500, loss: 8.715985
[2024-08-18 05:39:28,624::train::INFO] epoch: 39/60, iters: 1000/1500, loss: 8.716499
[2024-08-18 05:40:39,427::train::INFO] epoch: 39/60, iters: 1200/1500, loss: 8.720558
[2024-08-18 05:41:50,001::train::INFO] epoch: 39/60, iters: 1400/1500, loss: 8.721862
[2024-08-18 05:42:25,219::train::INFO] epoch: 39/60, avg epoch loss: 8.721002, time: 344 mins 3.9 secs
[2024-08-18 05:42:25,219::train::INFO] ********* Epoch 40 *********
[2024-08-18 05:43:36,299::train::INFO] epoch: 40/60, iters: 200/1500, loss: 8.744130
[2024-08-18 05:44:47,152::train::INFO] epoch: 40/60, iters: 400/1500, loss: 8.728210
[2024-08-18 05:45:58,145::train::INFO] epoch: 40/60, iters: 600/1500, loss: 8.721159
[2024-08-18 05:47:08,984::train::INFO] epoch: 40/60, iters: 800/1500, loss: 8.717889
[2024-08-18 05:48:19,704::train::INFO] epoch: 40/60, iters: 1000/1500, loss: 8.715187
[2024-08-18 05:49:30,436::train::INFO] epoch: 40/60, iters: 1200/1500, loss: 8.718549
[2024-08-18 05:50:41,264::train::INFO] epoch: 40/60, iters: 1400/1500, loss: 8.719634
[2024-08-18 05:51:16,238::train::INFO] epoch: 40/60, avg epoch loss: 8.719525, time: 352 mins 54.9 secs
[2024-08-18 05:51:16,251::train::INFO] ********* Epoch 41 *********
[2024-08-18 05:52:26,810::train::INFO] epoch: 41/60, iters: 200/1500, loss: 8.727073
[2024-08-18 05:53:37,370::train::INFO] epoch: 41/60, iters: 400/1500, loss: 8.704099
[2024-08-18 05:54:47,814::train::INFO] epoch: 41/60, iters: 600/1500, loss: 8.707951
[2024-08-18 05:55:58,661::train::INFO] epoch: 41/60, iters: 800/1500, loss: 8.705020
[2024-08-18 05:57:09,313::train::INFO] epoch: 41/60, iters: 1000/1500, loss: 8.703587
[2024-08-18 05:58:20,129::train::INFO] epoch: 41/60, iters: 1200/1500, loss: 8.710371
[2024-08-18 05:59:31,032::train::INFO] epoch: 41/60, iters: 1400/1500, loss: 8.712041
[2024-08-18 06:00:06,623::train::INFO] epoch: 41/60, avg epoch loss: 8.712267, time: 361 mins 45.3 secs
[2024-08-18 06:00:06,623::train::INFO] ********* Epoch 42 *********
[2024-08-18 06:01:17,858::train::INFO] epoch: 42/60, iters: 200/1500, loss: 8.713037
[2024-08-18 06:02:28,914::train::INFO] epoch: 42/60, iters: 400/1500, loss: 8.701026
[2024-08-18 06:03:39,995::train::INFO] epoch: 42/60, iters: 600/1500, loss: 8.706770
[2024-08-18 06:04:51,231::train::INFO] epoch: 42/60, iters: 800/1500, loss: 8.711111
[2024-08-18 06:06:02,099::train::INFO] epoch: 42/60, iters: 1000/1500, loss: 8.709615
[2024-08-18 06:07:13,397::train::INFO] epoch: 42/60, iters: 1200/1500, loss: 8.707605
[2024-08-18 06:08:24,672::train::INFO] epoch: 42/60, iters: 1400/1500, loss: 8.708549
[2024-08-18 06:09:00,238::train::INFO] epoch: 42/60, avg epoch loss: 8.707198, time: 370 mins 38.9 secs
[2024-08-18 06:09:00,238::train::INFO] ********* Epoch 43 *********
[2024-08-18 06:10:11,285::train::INFO] epoch: 43/60, iters: 200/1500, loss: 8.702930
[2024-08-18 06:11:21,834::train::INFO] epoch: 43/60, iters: 400/1500, loss: 8.702026
[2024-08-18 06:12:32,571::train::INFO] epoch: 43/60, iters: 600/1500, loss: 8.702318
[2024-08-18 06:13:43,393::train::INFO] epoch: 43/60, iters: 800/1500, loss: 8.705887
[2024-08-18 06:14:54,075::train::INFO] epoch: 43/60, iters: 1000/1500, loss: 8.702294
[2024-08-18 06:16:05,044::train::INFO] epoch: 43/60, iters: 1200/1500, loss: 8.703023
[2024-08-18 06:17:16,156::train::INFO] epoch: 43/60, iters: 1400/1500, loss: 8.705081
[2024-08-18 06:17:51,674::train::INFO] epoch: 43/60, avg epoch loss: 8.703178, time: 379 mins 30.4 secs
[2024-08-18 06:17:51,675::train::INFO] ********* Epoch 44 *********
[2024-08-18 06:19:02,574::train::INFO] epoch: 44/60, iters: 200/1500, loss: 8.723716
[2024-08-18 06:20:13,301::train::INFO] epoch: 44/60, iters: 400/1500, loss: 8.706077
[2024-08-18 06:21:24,034::train::INFO] epoch: 44/60, iters: 600/1500, loss: 8.711147
[2024-08-18 06:22:34,742::train::INFO] epoch: 44/60, iters: 800/1500, loss: 8.709591
[2024-08-18 06:23:45,649::train::INFO] epoch: 44/60, iters: 1000/1500, loss: 8.704652
[2024-08-18 06:24:56,738::train::INFO] epoch: 44/60, iters: 1200/1500, loss: 8.705735
[2024-08-18 06:26:07,782::train::INFO] epoch: 44/60, iters: 1400/1500, loss: 8.706197
[2024-08-18 06:26:43,173::train::INFO] epoch: 44/60, avg epoch loss: 8.705249, time: 388 mins 21.9 secs
[2024-08-18 06:26:43,173::train::INFO] ********* Epoch 45 *********
[2024-08-18 06:27:54,244::train::INFO] epoch: 45/60, iters: 200/1500, loss: 8.695429
[2024-08-18 06:29:04,979::train::INFO] epoch: 45/60, iters: 400/1500, loss: 8.707694
[2024-08-18 06:30:15,936::train::INFO] epoch: 45/60, iters: 600/1500, loss: 8.705061
[2024-08-18 06:31:27,025::train::INFO] epoch: 45/60, iters: 800/1500, loss: 8.706469
[2024-08-18 06:32:37,966::train::INFO] epoch: 45/60, iters: 1000/1500, loss: 8.702810
[2024-08-18 06:33:48,757::train::INFO] epoch: 45/60, iters: 1200/1500, loss: 8.705163
[2024-08-18 06:34:59,433::train::INFO] epoch: 45/60, iters: 1400/1500, loss: 8.704190
[2024-08-18 06:35:34,833::train::INFO] epoch: 45/60, avg epoch loss: 8.704055, time: 397 mins 13.5 secs
[2024-08-18 06:35:34,834::train::INFO] ********* Epoch 46 *********
[2024-08-18 06:36:46,021::train::INFO] epoch: 46/60, iters: 200/1500, loss: 8.700227
[2024-08-18 06:37:57,051::train::INFO] epoch: 46/60, iters: 400/1500, loss: 8.696784
[2024-08-18 06:39:07,809::train::INFO] epoch: 46/60, iters: 600/1500, loss: 8.702521
[2024-08-18 06:40:18,914::train::INFO] epoch: 46/60, iters: 800/1500, loss: 8.704318
[2024-08-18 06:41:29,644::train::INFO] epoch: 46/60, iters: 1000/1500, loss: 8.699995
[2024-08-18 06:42:40,578::train::INFO] epoch: 46/60, iters: 1200/1500, loss: 8.702681
[2024-08-18 06:43:51,404::train::INFO] epoch: 46/60, iters: 1400/1500, loss: 8.702848
[2024-08-18 06:44:26,951::train::INFO] epoch: 46/60, avg epoch loss: 8.702611, time: 406 mins 5.7 secs
[2024-08-18 06:44:26,951::train::INFO] ********* Epoch 47 *********
[2024-08-18 06:45:38,065::train::INFO] epoch: 47/60, iters: 200/1500, loss: 8.711461
[2024-08-18 06:46:49,182::train::INFO] epoch: 47/60, iters: 400/1500, loss: 8.699374
[2024-08-18 06:48:00,142::train::INFO] epoch: 47/60, iters: 600/1500, loss: 8.696443
[2024-08-18 06:49:11,143::train::INFO] epoch: 47/60, iters: 800/1500, loss: 8.701707
[2024-08-18 06:50:22,058::train::INFO] epoch: 47/60, iters: 1000/1500, loss: 8.697962
[2024-08-18 06:51:33,105::train::INFO] epoch: 47/60, iters: 1200/1500, loss: 8.697981
[2024-08-18 06:52:43,855::train::INFO] epoch: 47/60, iters: 1400/1500, loss: 8.700539
[2024-08-18 06:53:19,212::train::INFO] epoch: 47/60, avg epoch loss: 8.699542, time: 414 mins 57.9 secs
[2024-08-18 06:53:19,212::train::INFO] ********* Epoch 48 *********
[2024-08-18 06:54:30,212::train::INFO] epoch: 48/60, iters: 200/1500, loss: 8.688294
[2024-08-18 06:55:41,039::train::INFO] epoch: 48/60, iters: 400/1500, loss: 8.685748
[2024-08-18 06:56:51,865::train::INFO] epoch: 48/60, iters: 600/1500, loss: 8.688237
[2024-08-18 06:58:02,603::train::INFO] epoch: 48/60, iters: 800/1500, loss: 8.693602
[2024-08-18 06:59:13,297::train::INFO] epoch: 48/60, iters: 1000/1500, loss: 8.692703
[2024-08-18 07:00:23,831::train::INFO] epoch: 48/60, iters: 1200/1500, loss: 8.699841
[2024-08-18 07:01:34,481::train::INFO] epoch: 48/60, iters: 1400/1500, loss: 8.700940
[2024-08-18 07:02:09,866::train::INFO] epoch: 48/60, avg epoch loss: 8.698174, time: 423 mins 48.6 secs
[2024-08-18 07:02:09,866::train::INFO] ********* Epoch 49 *********
[2024-08-18 07:03:20,993::train::INFO] epoch: 49/60, iters: 200/1500, loss: 8.720558
[2024-08-18 07:04:32,042::train::INFO] epoch: 49/60, iters: 400/1500, loss: 8.698215
[2024-08-18 07:05:43,236::train::INFO] epoch: 49/60, iters: 600/1500, loss: 8.700317
[2024-08-18 07:06:54,230::train::INFO] epoch: 49/60, iters: 800/1500, loss: 8.702584
[2024-08-18 07:08:05,091::train::INFO] epoch: 49/60, iters: 1000/1500, loss: 8.704053
[2024-08-18 07:09:16,274::train::INFO] epoch: 49/60, iters: 1200/1500, loss: 8.703493
[2024-08-18 07:10:27,411::train::INFO] epoch: 49/60, iters: 1400/1500, loss: 8.700884
[2024-08-18 07:11:02,632::train::INFO] epoch: 49/60, avg epoch loss: 8.699860, time: 432 mins 41.3 secs
[2024-08-18 07:11:02,632::train::INFO] ********* Epoch 50 *********
[2024-08-18 07:12:13,651::train::INFO] epoch: 50/60, iters: 200/1500, loss: 8.702975
[2024-08-18 07:13:24,568::train::INFO] epoch: 50/60, iters: 400/1500, loss: 8.691395
[2024-08-18 07:14:35,530::train::INFO] epoch: 50/60, iters: 600/1500, loss: 8.693604
[2024-08-18 07:15:46,222::train::INFO] epoch: 50/60, iters: 800/1500, loss: 8.700231
[2024-08-18 07:16:57,169::train::INFO] epoch: 50/60, iters: 1000/1500, loss: 8.701246
[2024-08-18 07:18:07,949::train::INFO] epoch: 50/60, iters: 1200/1500, loss: 8.702605
[2024-08-18 07:19:19,189::train::INFO] epoch: 50/60, iters: 1400/1500, loss: 8.700578
[2024-08-18 07:19:54,610::train::INFO] epoch: 50/60, avg epoch loss: 8.696208, time: 441 mins 33.3 secs
[2024-08-18 07:19:54,623::train::INFO] ********* Epoch 51 *********
[2024-08-18 07:21:05,621::train::INFO] epoch: 51/60, iters: 200/1500, loss: 8.710481
[2024-08-18 07:22:16,864::train::INFO] epoch: 51/60, iters: 400/1500, loss: 8.705486
[2024-08-18 07:23:27,752::train::INFO] epoch: 51/60, iters: 600/1500, loss: 8.706951
[2024-08-18 07:24:38,472::train::INFO] epoch: 51/60, iters: 800/1500, loss: 8.704296
[2024-08-18 07:25:49,199::train::INFO] epoch: 51/60, iters: 1000/1500, loss: 8.701268
[2024-08-18 07:27:00,156::train::INFO] epoch: 51/60, iters: 1200/1500, loss: 8.702824
[2024-08-18 07:28:10,803::train::INFO] epoch: 51/60, iters: 1400/1500, loss: 8.700381
[2024-08-18 07:28:46,058::train::INFO] epoch: 51/60, avg epoch loss: 8.699119, time: 450 mins 24.8 secs
[2024-08-18 07:28:46,058::train::INFO] ********* Epoch 52 *********
[2024-08-18 07:29:56,983::train::INFO] epoch: 52/60, iters: 200/1500, loss: 8.706222
[2024-08-18 07:31:07,907::train::INFO] epoch: 52/60, iters: 400/1500, loss: 8.697940
[2024-08-18 07:32:18,947::train::INFO] epoch: 52/60, iters: 600/1500, loss: 8.697890
[2024-08-18 07:33:29,987::train::INFO] epoch: 52/60, iters: 800/1500, loss: 8.700672
[2024-08-18 07:34:40,978::train::INFO] epoch: 52/60, iters: 1000/1500, loss: 8.696988
[2024-08-18 07:35:52,008::train::INFO] epoch: 52/60, iters: 1200/1500, loss: 8.697194
[2024-08-18 07:37:02,632::train::INFO] epoch: 52/60, iters: 1400/1500, loss: 8.696091
[2024-08-18 07:37:38,011::train::INFO] epoch: 52/60, avg epoch loss: 8.696538, time: 459 mins 16.7 secs
[2024-08-18 07:37:38,011::train::INFO] ********* Epoch 53 *********
[2024-08-18 07:38:49,010::train::INFO] epoch: 53/60, iters: 200/1500, loss: 8.725298
[2024-08-18 07:40:00,389::train::INFO] epoch: 53/60, iters: 400/1500, loss: 8.706224
[2024-08-18 07:41:11,440::train::INFO] epoch: 53/60, iters: 600/1500, loss: 8.698759
[2024-08-18 07:42:22,335::train::INFO] epoch: 53/60, iters: 800/1500, loss: 8.699652
[2024-08-18 07:43:33,260::train::INFO] epoch: 53/60, iters: 1000/1500, loss: 8.696157
[2024-08-18 07:44:44,228::train::INFO] epoch: 53/60, iters: 1200/1500, loss: 8.692253
[2024-08-18 07:45:55,346::train::INFO] epoch: 53/60, iters: 1400/1500, loss: 8.695154
[2024-08-18 07:46:30,745::train::INFO] epoch: 53/60, avg epoch loss: 8.695445, time: 468 mins 9.5 secs
[2024-08-18 07:46:30,745::train::INFO] ********* Epoch 54 *********
[2024-08-18 07:47:41,703::train::INFO] epoch: 54/60, iters: 200/1500, loss: 8.699392
[2024-08-18 07:48:52,386::train::INFO] epoch: 54/60, iters: 400/1500, loss: 8.692775
[2024-08-18 07:50:02,929::train::INFO] epoch: 54/60, iters: 600/1500, loss: 8.696795
[2024-08-18 07:51:14,086::train::INFO] epoch: 54/60, iters: 800/1500, loss: 8.695383
[2024-08-18 07:52:25,325::train::INFO] epoch: 54/60, iters: 1000/1500, loss: 8.694407
[2024-08-18 07:53:36,265::train::INFO] epoch: 54/60, iters: 1200/1500, loss: 8.694751
[2024-08-18 07:54:46,948::train::INFO] epoch: 54/60, iters: 1400/1500, loss: 8.695130
[2024-08-18 07:55:22,075::train::INFO] epoch: 54/60, avg epoch loss: 8.695221, time: 477 mins 0.8 secs
[2024-08-18 07:55:22,076::train::INFO] ********* Epoch 55 *********
[2024-08-18 07:56:32,861::train::INFO] epoch: 55/60, iters: 200/1500, loss: 8.690092
[2024-08-18 07:57:43,934::train::INFO] epoch: 55/60, iters: 400/1500, loss: 8.690031
[2024-08-18 07:58:55,043::train::INFO] epoch: 55/60, iters: 600/1500, loss: 8.699719
[2024-08-18 08:00:06,274::train::INFO] epoch: 55/60, iters: 800/1500, loss: 8.699703
[2024-08-18 08:01:17,209::train::INFO] epoch: 55/60, iters: 1000/1500, loss: 8.693906
[2024-08-18 08:02:28,060::train::INFO] epoch: 55/60, iters: 1200/1500, loss: 8.695450
[2024-08-18 08:03:39,278::train::INFO] epoch: 55/60, iters: 1400/1500, loss: 8.694976
[2024-08-18 08:04:14,693::train::INFO] epoch: 55/60, avg epoch loss: 8.691368, time: 485 mins 53.4 secs
[2024-08-18 08:04:14,693::train::INFO] ********* Epoch 56 *********
[2024-08-18 08:05:25,821::train::INFO] epoch: 56/60, iters: 200/1500, loss: 8.722218
[2024-08-18 08:06:37,042::train::INFO] epoch: 56/60, iters: 400/1500, loss: 8.702696
[2024-08-18 08:07:47,914::train::INFO] epoch: 56/60, iters: 600/1500, loss: 8.699545
[2024-08-18 08:08:59,001::train::INFO] epoch: 56/60, iters: 800/1500, loss: 8.694546
[2024-08-18 08:10:09,760::train::INFO] epoch: 56/60, iters: 1000/1500, loss: 8.692248
[2024-08-18 08:11:20,718::train::INFO] epoch: 56/60, iters: 1200/1500, loss: 8.692775
[2024-08-18 08:12:31,629::train::INFO] epoch: 56/60, iters: 1400/1500, loss: 8.693302
[2024-08-18 08:13:06,764::train::INFO] epoch: 56/60, avg epoch loss: 8.692122, time: 494 mins 45.5 secs
[2024-08-18 08:13:06,764::train::INFO] ********* Epoch 57 *********
[2024-08-18 08:14:17,686::train::INFO] epoch: 57/60, iters: 200/1500, loss: 8.698956
[2024-08-18 08:15:28,637::train::INFO] epoch: 57/60, iters: 400/1500, loss: 8.695989
[2024-08-18 08:16:39,528::train::INFO] epoch: 57/60, iters: 600/1500, loss: 8.692768
[2024-08-18 08:17:50,220::train::INFO] epoch: 57/60, iters: 800/1500, loss: 8.690092
[2024-08-18 08:19:01,022::train::INFO] epoch: 57/60, iters: 1000/1500, loss: 8.689881
[2024-08-18 08:20:11,574::train::INFO] epoch: 57/60, iters: 1200/1500, loss: 8.693441
[2024-08-18 08:21:22,393::train::INFO] epoch: 57/60, iters: 1400/1500, loss: 8.694883
[2024-08-18 08:21:57,560::train::INFO] epoch: 57/60, avg epoch loss: 8.693878, time: 503 mins 36.3 secs
[2024-08-18 08:21:57,560::train::INFO] ********* Epoch 58 *********
[2024-08-18 08:23:08,557::train::INFO] epoch: 58/60, iters: 200/1500, loss: 8.700605
[2024-08-18 08:24:19,437::train::INFO] epoch: 58/60, iters: 400/1500, loss: 8.692849
[2024-08-18 08:25:29,869::train::INFO] epoch: 58/60, iters: 600/1500, loss: 8.702778
[2024-08-18 08:26:40,133::train::INFO] epoch: 58/60, iters: 800/1500, loss: 8.695905
[2024-08-18 08:27:50,861::train::INFO] epoch: 58/60, iters: 1000/1500, loss: 8.692630
[2024-08-18 08:29:01,656::train::INFO] epoch: 58/60, iters: 1200/1500, loss: 8.690538
[2024-08-18 08:30:12,543::train::INFO] epoch: 58/60, iters: 1400/1500, loss: 8.690237
[2024-08-18 08:30:47,736::train::INFO] epoch: 58/60, avg epoch loss: 8.688841, time: 512 mins 26.4 secs
[2024-08-18 08:30:47,737::train::INFO] ********* Epoch 59 *********
[2024-08-18 08:31:58,536::train::INFO] epoch: 59/60, iters: 200/1500, loss: 8.717264
[2024-08-18 08:33:09,615::train::INFO] epoch: 59/60, iters: 400/1500, loss: 8.699763
[2024-08-18 08:34:20,227::train::INFO] epoch: 59/60, iters: 600/1500, loss: 8.693819
[2024-08-18 08:35:31,160::train::INFO] epoch: 59/60, iters: 800/1500, loss: 8.695262
[2024-08-18 08:36:41,932::train::INFO] epoch: 59/60, iters: 1000/1500, loss: 8.691172
[2024-08-18 08:37:52,864::train::INFO] epoch: 59/60, iters: 1200/1500, loss: 8.692227
[2024-08-18 08:39:03,592::train::INFO] epoch: 59/60, iters: 1400/1500, loss: 8.691779
[2024-08-18 08:39:38,709::train::INFO] epoch: 59/60, avg epoch loss: 8.690455, time: 521 mins 17.4 secs
[2024-08-18 08:39:38,709::train::INFO] ********* Epoch 60 *********
[2024-08-18 08:40:49,036::train::INFO] epoch: 60/60, iters: 200/1500, loss: 8.706854
[2024-08-18 08:41:59,996::train::INFO] epoch: 60/60, iters: 400/1500, loss: 8.693713
[2024-08-18 08:43:10,845::train::INFO] epoch: 60/60, iters: 600/1500, loss: 8.686781
[2024-08-18 08:44:21,133::train::INFO] epoch: 60/60, iters: 800/1500, loss: 8.686295
[2024-08-18 08:45:31,964::train::INFO] epoch: 60/60, iters: 1000/1500, loss: 8.686042
[2024-08-18 08:46:42,845::train::INFO] epoch: 60/60, iters: 1200/1500, loss: 8.688256
[2024-08-18 08:47:53,980::train::INFO] epoch: 60/60, iters: 1400/1500, loss: 8.690116
[2024-08-18 08:48:29,389::train::INFO] epoch: 60/60, avg epoch loss: 8.688260, time: 530 mins 8.1 secs
